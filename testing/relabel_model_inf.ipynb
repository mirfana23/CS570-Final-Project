{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle relative importing\n",
    "import os\n",
    "import sys\n",
    "module_paths = [\n",
    "    os.path.abspath(os.path.join('..')),\n",
    "]\n",
    "for module_path in module_paths:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import necessary files\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "# dataloader\n",
    "from src.dataloaders.dataloader import ImgNetDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgnet 1k\n",
    "dataset = ImgNetDataset(\"/root/CS570-Final-Project/datasets/imgnet1k_original/val.json\", type='val')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1042/50000 [00:10<09:47, 83.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2070/50000 [00:20<09:47, 81.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78662109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3091/50000 [00:31<09:30, 82.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4119/50000 [00:41<08:30, 89.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5141/50000 [00:51<08:13, 90.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6153/50000 [01:01<07:09, 102.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7181/50000 [01:14<10:47, 66.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 8212/50000 [01:26<08:01, 86.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8741/50000 [01:31<07:13, 95.23it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m img_path \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mimg_path\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(img_path)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m     34\u001b[0m             transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     35\u001b[0m             transforms\u001b[39m.\u001b[39mResize(\u001b[39m256\u001b[39m, antialias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     36\u001b[0m             transforms\u001b[39m.\u001b[39mCenterCrop(\u001b[39m224\u001b[39m),\n\u001b[1;32m     37\u001b[0m             transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m]),\n\u001b[1;32m     38\u001b[0m ])(img)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     39\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     41\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(item[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/cs570_t23/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/cs570_t23/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mto_tensor(pic)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs570_t23/lib/python3.11/site-packages/torchvision/transforms/functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mview(pic\u001b[39m.\u001b[39msize[\u001b[39m1\u001b[39m], pic\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m], F_pil\u001b[39m.\u001b[39mget_image_num_channels(pic))\n\u001b[1;32m    171\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# resnet50 torch\n",
    "\n",
    "import time\n",
    "from torchvision import transforms\n",
    "\n",
    "resnet50 = torchvision.models.resnet50()\n",
    "load_from_checkpoint = '/root/CS570-Final-Project/pt_models/rn50_relabel_78.9.pth'\n",
    "state_dict = torch.load(load_from_checkpoint)\n",
    "items = list(state_dict.items())\n",
    "for k, v in items:\n",
    "    if k.startswith('module.'):\n",
    "        state_dict[k[len('module.'):]] = state_dict.pop(k)\n",
    "resnet50.load_state_dict(state_dict)\n",
    "resnet50.eval()\n",
    "resnet50.cuda()\n",
    "\n",
    "json_path = '/root/CS570-Final-Project/datasets/imgnet1k_original/val.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    json_data = json_data['data']\n",
    "    # random.shuffle(json_data)\n",
    "\n",
    "acc, cnt = 0, 0\n",
    "ms = 1000\n",
    "B = 256\n",
    "img_L, labels_L = [], []\n",
    "for idx, item in enumerate(tqdm(json_data)):\n",
    "    start_time = time.time()\n",
    "    img_path = item['img_path']\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize(256, antialias=True),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])(img).unsqueeze(0).cuda()\n",
    "    end_time = time.time()\n",
    "\n",
    "    labels = torch.tensor(item['labels'])\n",
    "    y = torch.zeros(1000)\n",
    "    if len(labels) > 0:\n",
    "        y[labels] = 1\n",
    "\n",
    "    y = y.unsqueeze(0).cuda()\n",
    "\n",
    "    img_L.append(img)\n",
    "    labels_L.append(y)\n",
    "\n",
    "    if len(img_L) == B or idx == len(json_data) - 1:\n",
    "        img = torch.cat(img_L, dim=0)\n",
    "        y = torch.cat(labels_L, dim=0)    \n",
    "        img_L, labels_L = [], []    \n",
    "        with torch.no_grad():\n",
    "            output = resnet50(img)\n",
    "            p_idx = output.argmax(dim=1)\n",
    "            gt_idx = y.argmax(dim=1)\n",
    "            acc += (p_idx == gt_idx).sum().item()\n",
    "            cnt += len(p_idx)\n",
    "        if cnt > ms:\n",
    "            print(acc / cnt)\n",
    "            ms += 1000\n",
    "print(acc / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs570_t23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
